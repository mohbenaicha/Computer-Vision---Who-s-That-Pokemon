{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SCS_3546_Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnvVdcQSiKMA"
      },
      "source": [
        "# Set-up and import data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "XkrMh4W0g4kQ",
        "outputId": "69ddfc3e-7b1a-4a95-adaf-297f431f5612"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-75cdc7b3-703b-4626-8e3c-af33e383cb47\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-75cdc7b3-703b-4626-8e3c-af33e383cb47\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample_repository (1).json to sample_repository (1).json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VlWbMwpg4u5"
      },
      "source": [
        "import json \n",
        "\n",
        "with open('sample_repository (1).json') as in_file:\n",
        "    test_data = json.load(in_file)\n",
        "\n",
        "titles = [item[0] for item in test_data['data']]\n",
        "documents = [item[1] for item in test_data['data']]"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKAF8OSPCFf5"
      },
      "source": [
        "# titles[:32], documents[:32]"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1zBu6DIjdtP"
      },
      "source": [
        "# 1. TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kiMbXxZKCDE"
      },
      "source": [
        "## **Conclusion for semantic segmentation using TF-IDF vectorizer (with and without preprocessing):**\n",
        "\n",
        "\n",
        "\n",
        "1.   TFIDF seems to work decently for single words as well as for multiple word queries. However, TFIDF seems to neglect context to a certain as opposed to BERT which will soon see considers context. Compared to GloVe, TFIDF does \"contecualize\" a bit better since it looks at both term and document frequency. That is why for the queries \"fruit\" and \"vegetable\" it did not return specific documents such as \"fruit serving bowl\" and \"white onions\" and instead returned nutrition and major market as the titled for the most relevant documents to the  queriesres \"fruit\" and \"vegetable\", respectively.\n",
        "2.   TFIDF with lemmatization and punctuation removal preprocessing generated different results than for the unpreprocessed documents. That is because TFIDF was probably able to identify greater frequency when words were lemmatized. Removing punctuations did not have an effect since the queries generated the same top scoring documents as in the punctuated TFIDF implemenetation. This is likely due to the non-discriminative role of punctuation since they don't really help to distinguish a document so they're given a low score. \n",
        "3.   TFIDF works better than \"GloVe\" in semantic segmentation as the latter seems to have trouble retrieving relevant documents to queries with multiple words since it's vectors are built based on a dictionary of tokens. When the query of \"healthy foods in Canada\" is done in tokens as in [\"healthy\", \"foods\", \"in\", \"Canada\"], GloVe returns reasonable results such as documents titled \"Canada's Food Guide\", 'Diet', 'fruit serving bowl', etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XP9_ncYg4yu",
        "outputId": "c0b46e9a-3961-4e06-cf4f-de62954b9527"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.corpora import Dictionary\n",
        "import gensim.downloader as api\n",
        "from gensim.models import TfidfModel\n",
        "nltk.download('wordnet')\n",
        "\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym076HWMg42r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ede0ade9-64b5-4ae1-8e4c-14584d12628a"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "query = 'fruits'\n",
        "query_terms = ['fruits', 'vegetables', 'healthy foods in Canada']\n",
        "\n",
        "# instantiate TDIDF vectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
        "\n",
        "# Vecorizes every word in every document accordint to a TF x IDF approach and generates a sparse matrix in the following format:\n",
        "# (x, y) z: x -> document, y -> word id/index, z -> TD x IDF score\n",
        "vectors = vectorizer.fit_transform([query_terms[0]] + documents) \n",
        "\n",
        "# Calculate the word frequency, and a measure of similarity (whatever you find it to be approperiate) of the search terms with each document\n",
        "print(\"TFIDF for documents are:\\n\",vectors[:2], \"\\n\")\n",
        "\n",
        "\n",
        "# Print the top-scoring results and their titles\n",
        "\n",
        "# Here I'm using cosine similarity based on linear kernels, an approached advised at: https://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity\n",
        "# Intuition behind cosine similarity: it essentially gets the \"angle\" - in degrees - between two vectors representing our query document and the documents in the corpus that we're comapring\n",
        "# our query to, and ranks them in order as in product of vectors divided by product of their (vectors) standardized form as in: np.dot(a, b)//np.dot(abs(a),abs(b))\n",
        "\n",
        "for i in query_terms:\n",
        "  vectors = vectorizer.fit_transform([i] + documents) # another approach would simply be to include all query words as individual documents\n",
        "  cosine_similarities = linear_kernel(vectors[:1], vectors).flatten() # first vector represents my first document (as in my query) that is compared to all of the vectors - documents\n",
        "  related_docs_indices = cosine_similarities.argsort()[:-10:-1][1] # taking index 1 since index 0 is actually our query so it has a perfect cosine similarity score\n",
        "  print(\"The top scoring document relevant to {}\".format(i), \" is: \", titles[related_docs_indices])"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFIDF for documents are:\n",
            "   (0, 260)\t1.0\n",
            "  (1, 39)\t0.10409377510849337\n",
            "  (1, 36)\t0.10409377510849337\n",
            "  (1, 434)\t0.07430797619476548\n",
            "  (1, 421)\t0.10409377510849337\n",
            "  (1, 395)\t0.10409377510849337\n",
            "  (1, 613)\t0.10409377510849337\n",
            "  (1, 323)\t0.08304429837808315\n",
            "  (1, 43)\t0.08304429837808315\n",
            "  (1, 133)\t0.17716206996595776\n",
            "  (1, 162)\t0.10409377510849337\n",
            "  (1, 560)\t0.09535745292517571\n",
            "  (1, 565)\t0.08858103498297888\n",
            "  (1, 139)\t0.11640692965558593\n",
            "  (1, 38)\t0.10409377510849337\n",
            "  (1, 364)\t0.10409377510849337\n",
            "  (1, 11)\t0.10409377510849337\n",
            "  (1, 378)\t0.10409377510849337\n",
            "  (1, 190)\t0.08858103498297888\n",
            "  (1, 1)\t0.10409377510849337\n",
            "  (1, 47)\t0.1660885967561663\n",
            "  (1, 119)\t0.10409377510849337\n",
            "  (1, 604)\t0.31228132532548014\n",
            "  (1, 388)\t0.20818755021698673\n",
            "  (1, 420)\t0.07430797619476548\n",
            "  :\t:\n",
            "  (1, 531)\t0.10409377510849337\n",
            "  (1, 326)\t0.11640692965558593\n",
            "  (1, 610)\t0.10409377510849337\n",
            "  (1, 259)\t0.1660885967561663\n",
            "  (1, 335)\t0.09535745292517571\n",
            "  (1, 521)\t0.11640692965558593\n",
            "  (1, 469)\t0.11640692965558593\n",
            "  (1, 606)\t0.11640692965558593\n",
            "  (1, 66)\t0.11640692965558593\n",
            "  (1, 220)\t0.11640692965558593\n",
            "  (1, 530)\t0.08858103498297888\n",
            "  (1, 502)\t0.11640692965558593\n",
            "  (1, 445)\t0.11640692965558593\n",
            "  (1, 73)\t0.20818755021698673\n",
            "  (1, 488)\t0.2972319047790619\n",
            "  (1, 177)\t0.11640692965558593\n",
            "  (1, 302)\t0.10409377510849337\n",
            "  (1, 595)\t0.10409377510849337\n",
            "  (1, 455)\t0.11640692965558593\n",
            "  (1, 103)\t0.23281385931117185\n",
            "  (1, 313)\t0.059564086646699474\n",
            "  (1, 81)\t0.059564086646699474\n",
            "  (1, 65)\t0.059564086646699474\n",
            "  (1, 450)\t0.20818755021698673\n",
            "  (1, 258)\t0.07430797619476548 \n",
            "\n",
            "The top scoring document relevant to fruits  is:  Nutrition\n",
            "The top scoring document relevant to vegetables  is:  Major Market\n",
            "The top scoring document relevant to healthy foods in Canada  is:  Major Market\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqrN27J9mZwb"
      },
      "source": [
        "## Repeat the same task after some preprocessing \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSsdfQb9g46z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb9fe77-11b7-4a40-921c-bde728140ed4"
      },
      "source": [
        "# Preprocessing: Lemmatization\n",
        "# This is a strightforward lemmatization applied by toneizing words in documents then rejoining them\n",
        "# and conducting the same queries as above\n",
        "\n",
        "from nltk import word_tokenize          \n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemm = WordNetLemmatizer()\n",
        "\n",
        "# Here, words in a sentence are seperated into individual token strings\n",
        "# to each word in each document of the corpus\n",
        "docs = []\n",
        "for i in documents:\n",
        "  docs.append(nltk.word_tokenize(i))\n",
        "lemm = WordNetLemmatizer()\n",
        "\n",
        "# Here, we're getting the \"root\" of each word in each document of the corpus\n",
        "documents = []\n",
        "for doc in range(len(docs)):\n",
        "  sent = ' '.join([lemm.lemmatize(word) for word in docs[doc]])\n",
        "  documents.append(sent)\n",
        "\n",
        "# As in the non-preprocessed TFIDF application above\n",
        "for i in query_terms:\n",
        "  vectors = vectorizer.fit_transform([i] + documents) \n",
        "  cosine_similarities = linear_kernel(vectors[:1], vectors).flatten()\n",
        "  related_docs_indices = cosine_similarities.argsort()[:-10:-1][1]\n",
        "  print(\"Most relevant document to {}\".format(i), \" is: \", titles[related_docs_indices])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most relevant document to fruits  is:  Pink Onions\n",
            "Most relevant document to vegetables  is:  Pink Onions\n",
            "Most relevant document to healthy foods in Canada  is:  Major Market\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCqqli9H9R_O",
        "outputId": "faa1747f-e32f-4ebd-887e-39ac3cbfb51e"
      },
      "source": [
        "# Preprocessing: Lemmatization + punctuation removal\n",
        "from nltk.tokenize import RegexpTokenizer as regextk\n",
        "\n",
        "# Here I ustilize regex tokenier that tokenizes and regularizes expressions that have already been lemmatize above\n",
        "rgtk = regextk(r'\\w+') # removes punctuation according to: https://www.kite.com/python/answers/how-to-remove-all-punctuation-marks-with-nltk-in-python\n",
        "docs = []\n",
        "for doc in documents:\n",
        "  sent = ' '.join(rgtk.tokenize(doc))\n",
        "  docs.append(sent)\n",
        "\n",
        "# As in the non-preprocessed TFIDF application above\n",
        "for i in query_terms:\n",
        "  vectors = vectorizer.fit_transform([i] + docs)\n",
        "  cosine_similarities = linear_kernel(vectors[:1], vectors).flatten()\n",
        "  related_docs_indices = cosine_similarities.argsort()[:-10:-1][1]\n",
        "  print(\"Most relevant document to {}\".format(i), \" is: \", titles[related_docs_indices])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most relevant document to fruits  is:  Pink Onions\n",
            "Most relevant document to vegetables  is:  Pink Onions\n",
            "Most relevant document to healthy foods in Canada  is:  Major Market\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8V2kx6Epnxq"
      },
      "source": [
        "# 2. Semantic matching using GloVe embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTH8YqiQJjo6"
      },
      "source": [
        "##**Conclusion for semantic segmentation using GloVe embeddings:**\n",
        "- GloVe embeddings handle single word queries but seem to run into \n",
        "problems when handling sentence queries according to my experience (unless I made a mistake).\n",
        "\n",
        "- The queries for fruits and vegetables are very relevant - doing better than TFIDF in terms of retrieving the most relevant vector under fruits (TFIDF returns \"white onions\" as the title of the document that is most relevant to \"fruit\"), and the results for \"Healthy foods in Canada\" only returned relevant results when the string was broken into individual tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGBg_Roo8FvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f08ea977-5ce8-4053-ef34-7d0e6ae04dc6"
      },
      "source": [
        "# !pip install  gensim==4.0.1 # if you decide to use the gensim library and the sample codes below, you would need gensim version >=4.0.1 to be installed \n",
        "import gensim\n",
        "print(gensim.__version__)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oywLsqBYrayZ"
      },
      "source": [
        "import logging\n",
        "import logging\n",
        "from re import sub\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "import gensim.downloader as api\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.similarities import WordEmbeddingSimilarityIndex\n",
        "from gensim.similarities import SparseTermSimilarityMatrix\n",
        "from gensim.similarities import SoftCosineSimilarity"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa0dlD102lbp"
      },
      "source": [
        "import logging\n",
        "\n",
        "# Initialize logging.\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.WARNING)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwQBtaxk5rXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "923b3c7f-ad66-4d36-9f94-19d994ee39f9"
      },
      "source": [
        "import nltk\n",
        "\n",
        "# Import and download stopwords from NLTK.\n",
        "nltk.download('stopwords')  # Download stopwords list.\n",
        "stopwords = set(nltk.corpus.stopwords.words(\"english\"))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mlGyZeZ2Nle"
      },
      "source": [
        "def preprocess(doc):\n",
        "    # Tokenize, clean up input document string remvoing special characters, etc. to prepare it for BoW\n",
        "    doc = sub(r'<img[^<>]+(>|$)', \" image_token \", doc)\n",
        "    # you may decide to add additional steps here \n",
        "    return [token for token in simple_preprocess(doc, min_len=0, max_len=float(\"inf\")) if token not in stopwords]"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP1s_4hMpqAn"
      },
      "source": [
        "# Load test data\n",
        "with open('sample_repository (1).json') as in_file:\n",
        "    test_data = json.load(in_file)\n",
        "\n",
        "titles = [item[0] for item in test_data['data']]\n",
        "documents = [item[1] for item in test_data['data']]"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaVXOXGDpqD5"
      },
      "source": [
        "query_s = ['fruits', 'vegetables', 'healthy foods in Canada']\n",
        "\n",
        "# This applies the preprocess function above to the documents, including the query string\n",
        "corpus = [preprocess(document) for document in documents]\n",
        "query = [preprocess(i) for i in query_terms]\n",
        "# query[2] = [' '.join(query[2])]"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR_F5zkipqH7"
      },
      "source": [
        "# Download and load the GloVe word vector embeddings\n",
        "\n",
        "if 'glove' not in locals():  # only load if not already in memory\n",
        "    glove = api.load(\"glove-wiki-gigaword-50\")\n",
        "\n",
        "similarity_index = WordEmbeddingSimilarityIndex(glove)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtWEI622pqLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296c5346-3871-4518-f844-2f25aad7632a"
      },
      "source": [
        "# Build the term dictionary, TF-idf model\n",
        "# Keep in mind that the search query must be in the dictionary as well, in case the terms do not overlap with the documents  \n",
        "\n",
        "dictionary = Dictionary(query + corpus) # query includes all 3 queries\n",
        "tfidf = TfidfModel(dictionary=dictionary)\n",
        "\n",
        "# Create the term similarity matrix. \n",
        "# The nonzero_limit enforces sparsity by limiting the number of non-zero terms in each column. \n",
        "# For my application, I got best results by removing the default value of 100\n",
        "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary, tfidf, nonzero_limit=None)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 568/568 [00:14<00:00, 39.03it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz8Vo-23NPf4"
      },
      "source": [
        "import warnings"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn9tPObFpqPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6513e55a-7fc1-4154-cad5-2e0393ebff88"
      },
      "source": [
        "# Compute similarity measure between the query and the documents.\n",
        "\n",
        "# The top 5/10 documents can be retrieved for the highest cosine similarities (indicating the smallest angle between 2 vectors representing 2 documents)\n",
        "# in order of largest to smallest of 32 consine score:\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "\n",
        "  for i in query_terms:\n",
        "    query_tf = tfidf[dictionary.doc2bow([i])]\n",
        "\n",
        "    index = SoftCosineSimilarity(\n",
        "                tfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
        "                similarity_matrix)\n",
        "\n",
        "    doc_similarity_scores = index[query_tf]\n",
        "    # if more than 1 document exists that is similar and it's score is not \n",
        "    if len((doc_similarity_scores).flatten()) > 0 and (doc_similarity_scores).flatten()[0] !=0 : \n",
        "      print(\"The top 10 related documents to: \\t{} \\t are:\\t\".format(i), [titles[j] for j in np.argsort(doc_similarity_scores)[:-10:-1]])\n",
        "    # if doc similarity score are 0\n",
        "    else: \n",
        "      print(\"No related documents to: \\t{} (see next cell)\".format(i))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 10 related documents to: \tfruits \t are:\t ['Pomegranate Bhagwa', 'Pomegranate Arakta', \"Canada's Food Guide\", 'Food classes', 'List of fruit dishes', 'fruit serving bowl', 'Grapes Flame / Red Seedless', 'history of botany', 'About Us']\n",
            "The top 10 related documents to: \tvegetables \t are:\t [\"Canada's Food Guide\", 'White Onions', 'Tomatoes', 'Food classes', 'fruit serving bowl', 'Red Onions', 'Pink Onions', 'List of fruit dishes', 'Pomegranate Arakta']\n",
            "No related documents to: \thealthy foods in Canada (see next cell)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRo7_vCdQDmK",
        "outputId": "85444590-278d-4f42-f936-d442cd8cd312"
      },
      "source": [
        "# Since no related documents are generated when a string \"healthy foods in Canada\" is queried, we can try querying individual terms together:\n",
        "\n",
        "query_tf = tfidf[dictionary.doc2bow([\"healthy\", \"foods\", \"in\", \"Canada\"])]\n",
        "with warnings.catch_warnings():\n",
        "  warnings.simplefilter(\"ignore\")\n",
        "  index = SoftCosineSimilarity(\n",
        "              tfidf[[dictionary.doc2bow(document) for document in corpus]],\n",
        "              similarity_matrix)\n",
        "  doc_similarity_scores = index[query_tf]\n",
        "  print(\"The top 10 related documents to: \\t{} \\t are:\\t\".format(i), [titles[j] for j in np.argsort(doc_similarity_scores)[:-10:-1]])"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 10 related documents to: \thealthy foods in Canada \t are:\t [\"Canada's Food Guide\", 'Diet', 'fruit serving bowl', 'Pomegranate Bhagwa', 'Pomegranate Arakta', 'Tomatoes', 'Nutrition', 'Grapes Black Sharad Seedless', 'About Us']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8at07gGAI-MH"
      },
      "source": [
        "# 3. BERT\n",
        "Use a bert model to create sentence embeddings and calculate the similarity between queries and documents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibKDiAkAHzTS"
      },
      "source": [
        "## **Conclusions for semantic segmentation using BERT**\n",
        "\n",
        "- I've opted to use NLI Sentence BERT utilizing max pooling from the spaCy API. NLI Sentence BERT seems to have much more relevant as they relate queries to documents based on 3 types of inference: entailment, contradiction and neutrality. The pooled output helps give one overall \"topic\" to a document further helping us in querying.\n",
        "\n",
        "- The conclusions are thet BERT embedding work far better and retrieve more relevant documents as they relate to the queries since BERT contexualizes in that it anaysez sequences both forwards and backwards making it ideal for topic modelling and retrieving relevant documents to the queries and their respective titles. For example,  for \"fruit\" the top 5 most relevant titles that all relate to fruit directly are: \n",
        "\n",
        "List of fruit dishes\n",
        "\n",
        "Food classes\n",
        "\n",
        "fruit serving bowl\n",
        "\n",
        "Pomegranate Arakta\n",
        "\n",
        "Pomegranate Bhagwa\n",
        "\n",
        "- I have also tried roberta base and roberta large and they did not yield better results. I have not tried the standard BERT such the configurations found in Kerashub since online discussions have advised against using the standard BERT and referred interested people to Sentence BERT for topic modelling and semantic segmentation.\n",
        "- In comaprison to TDIDF and GloVe, it appearsthat NLI BERT's resulting documents from the query were much more relevant to the query given their overall entailed meaning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBSozs_tYFjg"
      },
      "source": [
        "# ! pip3 install spacy --quiet\n",
        "# ! pip3 install spacy-transformers --quiet\n",
        "# ! pip3 install spacy_sentence_bert\n",
        "\n",
        "import spacy\n",
        "import spacy_transformers\n",
        "import spacy_sentence_bert"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Evfgq990mlcI"
      },
      "source": [
        "nlp = spacy_sentence_bert.load_model('en_nli_bert_large_max_pooling') # this BERT uses natural language inference and uses max pooled output (a single output of the sequence)\n",
        "\n",
        "# Utility function for generating sentence embedding from the text\n",
        "def embed(x):\n",
        "    '''\n",
        "    Applies BERT embedding to a document and returned a vector of embeddings of size n_documents x 768 or 1024 depending on the which BERT is used, the third dimension\n",
        "    '''\n",
        "    return nlp(x).vector\n",
        "\n",
        "# Generating sentence embedding from the text for each query for easy analysis later on\n",
        "embeddings1 = [embed(doc) for doc in documents + [query_terms[0]]]\n",
        "embeddings2 = [embed(doc) for doc in documents + [query_terms[1]]]\n",
        "embeddings3 = [embed(doc) for doc in documents + [query_terms[2]]]\n",
        "\n",
        "# np.array(embeddings1).shape"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raaQrNXUKL2o"
      },
      "source": [
        "# compare the findings  "
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLH7jBj4KL7E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4804ae38-8f19-48fe-d349-02c3cb1ef355"
      },
      "source": [
        "embeddings = [embeddings1, embeddings2, embeddings3]\n",
        "\n",
        "# this applies cosine similarity as explained in the TFIDF section\n",
        "for i, j in zip(query_terms, embeddings):\n",
        "  cosine_similarities = linear_kernel(j[-1].reshape(1,-1), j).flatten()\n",
        "  related_docs_indices = cosine_similarities.argsort()[:-10:-1]\n",
        "  print(\"\\nMost relevant document to '{}' is: \".format(i))\n",
        "  for i in related_docs_indices:\n",
        "    try: print(titles[i])\n",
        "    except: pass # exception for handle the fact that title list length = 32, vector list length = 33 since we included out query as a vector for easy application of cosine similarity"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Most relevant document to 'fruits' is: \n",
            "List of fruit dishes\n",
            "Food classes\n",
            "fruit serving bowl\n",
            "Pomegranate Arakta\n",
            "Pomegranate Bhagwa\n",
            "Welcome to Anushka Avni International (AAI)\n",
            "Tomatoes\n",
            "Diet\n",
            "\n",
            "Most relevant document to 'vegetables' is: \n",
            "Diet\n",
            "Nutrition\n",
            "Nutrients\n",
            "Food classes\n",
            "fruit serving bowl\n",
            "List of fruit dishes\n",
            "Welcome to Anushka Avni International (AAI)\n",
            "Canada's Food Guide\n",
            "\n",
            "Most relevant document to 'healthy foods in Canada' is: \n",
            "Canada's Food Guide\n",
            "Video Gallery\n",
            "Downloads\n",
            "Welcome to Anushka Avni International (AAI)\n",
            "White Onions\n",
            "About Us\n",
            "Contact Us\n",
            "Canadian Industry Statistics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YGLkmiTg_JL"
      },
      "source": [
        "# Comparisons\n",
        "\n",
        "1. Context: BERT overall understandas context much better which is why it was able to retrieve documents that were more relevant to queries like fruit, vegetable, or healthy foods in canada, where as TFIDF and GloVe simply seemed to \"count\" the number of occurance of a query in other documents or the overall corpus and retrieve the most relevant documents based on that and generally ignore context.\n",
        "2. Relevance: GloVe and BERT were both able to return relatively \"relevant\" documents to the queries whereas TFIDF at times returned documents that were quite \"off\" such as the example of returning the document titled \"white onions\" for the query \"fruit\".\n",
        "3. Querying sentences: BERT handled querying multiple words such as \"healthy foods in Canada\" much better than TFIDF and certainly much better than GloVe since BERT handles context of sequences meaning a sequence query didn't pose a problem for it. TFIDF was the next best at querying multiple words since it used word counts both within a single document and within the corpus. GloVe did not handle lengthy queries well since it specialisez in word-word co-occurence, instead, a sentence query should be split up and the component words queried together."
      ]
    }
  ]
}